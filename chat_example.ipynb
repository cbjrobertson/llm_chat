{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bba4e41-b1e6-499b-8276-ed0dd02ec2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0658e58c-4582-4f83-8734-edde2480c797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA A100 80GB PCIe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)\n",
    "#ablation tool: https://transformer-circuits.pub/2021/garcon/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e251b2-0548-4675-9377-786648f939aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate==0.25.0\n",
      "appdirs==1.4.4\n",
      "loralib\n",
      "bitsandbytes\n",
      "black==23.12.0\n",
      "black==23.12.0\n",
      "datasets==2.15.0\n",
      "fire==0.5.0\n",
      "peft==0.7.1\n",
      "transformers==4.36.2\n",
      "sentencepiece==0.1.99\n",
      "py7zr==0.20.8\n",
      "scipy==1.11.4\n",
      "optimum\n",
      "openai==1.5.0\n",
      "spacy==3.6.1\n"
     ]
    }
   ],
   "source": [
    "with open(\"requirements.txt\", \"r\") as f:\n",
    "    r = [x.strip().split(\"==\")[0].split(\">=\")[0].split(\"[\")[0] for x in f.readlines()][:-1]\n",
    "    \n",
    "import importlib\n",
    "for name in r:\n",
    "    module = importlib.import_module(name)\n",
    "    try:\n",
    "        print(f\"{name}=={module.__version__}\")\n",
    "    except Exception as e:\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f96112e-0c1b-42f4-8dcd-751797fe7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV SET UP\n",
    "# conda create -n llm_chat2 python=3.10 ipykernel ipywidgets\n",
    "# conda activate llm_chat2\n",
    "# conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "# git clone https://github.com/cbjrobertson/llm_chat.git\n",
    "# cd llm_chat\n",
    "# pip install -r requirements.txt\n",
    "# python setup.py install --record files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e741bfc-16c8-47d3-bc8e-045b919ee940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL hf creation\n",
    "# The first three model_names are local huggingface versions of the llama models, i.e. after downloading the meta weights, they were created following \n",
    "# the llama-recipes quickstart.ipynb directions, from: https://github.com/facebookresearch/llama-recipes/blob/main/quickstart.ipynb\n",
    "\n",
    "# i.e.:\n",
    "# %%bash\n",
    "# pip install transformers datasets accelerate sentencepiece protobuf==3.20 py7zr scipy peft bitsandbytes fire torch_tb_profiler ipywidgets\n",
    "# TRANSFORM=`python -c \"import transformers;print('/'.join(transformers.__file__.split('/')[:-1])+'/models/llama/convert_llama_weights_to_hf.py')\"`\n",
    "# print(TRANSFORM)\n",
    "# python ${TRANSFORM} --input_dir ./models/llama-2-70b-chat --model_size 70B --output_dir ./models_hf/70B_chat\n",
    "\n",
    "# NB, for the above code to work, meta weights need to be stored in a `models` dir using the following structure, where\n",
    "# each model is stored in a sub-directory in <<input_dir>> which matches the --model_size param, e.g. 7B, 13B, 70B:\n",
    "# ├── models\n",
    "# │   ├── llama-2-13b\n",
    "# │   │   └── 13B\n",
    "# │   ├── llama-2-13b-chat\n",
    "# │   │   └── 13B\n",
    "# │   ├── llama-2-70b\n",
    "# │   │   └── 70B\n",
    "# │   ├── llama-2-70b-chat\n",
    "# │   │   └── 70B\n",
    "# │   ├── llama-2-7b\n",
    "# │   │   └── 7B\n",
    "# │   └── llama-2-7b-chat\n",
    "# │       └── 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7006794-fb0b-4cb5-a39a-f1ac34f7dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from psy_llm_chat class to chat with GPT and Llama\n",
    "import psy_llm_chat as plc\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c9d53f-4607-4dc8-abcd-973e3101b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple dialog\n",
    "test_dialog = [\n",
    "    # {'role': 'system', 'content': 'Always answer with Haiku'},\n",
    "    {'role': 'user', 'content': \"If you can hear me say hi.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc97ae85-2e0e-4cbf-a735-6e00cf887196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3e6afbcd21453a9d515b445a84cbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  #local models \n",
    "# model_name =\"./llama_models/models_hf/7B_chat\"\n",
    "# model_name =\"./llama_models/models_hf/13B_chat\"\n",
    "# model_name =\"./llama_models/models_hf/70B_chat\"\n",
    "\n",
    "# # huggingface\n",
    "# models can also be loaded from HF hub (once access has been granted), e.g.:\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "# model_name = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "# load the model defined by <<model_name>>, must set output_hidden_states and ...attentions to True to access these later.\n",
    "lc = plc.LlamaChat(model_name, True, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5516e4-3104-4258-a95f-4b59ed7a28ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: If you can hear me say hi.\n",
      "Assistant: \n",
      "Hi there! *giggles* It's great to hear from you! How are you doing today? Is there anything on your mind that you want to talk about? I'm here to listen and help in any way I can. *smiles*\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  END_THIS_NOW\n"
     ]
    }
   ],
   "source": [
    "# run the chat by calling the class\n",
    "# to end the chat, input `END_THIS_NOW`; this terminates the chat and returns the dialog \n",
    "result = lc(test_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09de6c99-0eb9-4338-a937-901cddc7cfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'If you can hear me say hi.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"\\nHi there! *giggles* It's great to hear from you! How are you doing today? Is there anything on your mind that you want to talk about? I'm here to listen and help in any way I can. *smiles*\"},\n",
       " {'role': 'user', 'content': 'END_THIS_NOW'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dialog is a list of dicts\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cbbacb-6b9b-4ec1-a156-c11568d1ef8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning encoding for:\n",
      "\n",
      "--------------------\n",
      "\n",
      "[INST] If you can hear me say hi. [/INST]\n",
      " Hi there! *giggles* It's great to hear from you! How are you doing today? Is there anything on your mind that you want to talk about? I'm here to listen and help in any way I can. *smiles* \n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# allign spacy token boundaries with  embeddings with sentence piece embeddings and expose as the spacy.Token._.llama_vec Token property\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# pass spacy nlp object, result[:-1] (to avoid encoding END_THIS_NOW) and layer number (i.e. the layer from which to extract hidden state\n",
    "doc = lc.get_spacy_doc(nlp,result[:-1],layer=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca9955d-e3f9-44ec-a560-d846f6795155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of sentence-piece embeddings for: `hi`\n",
      "at doc index: `9`\n",
      "is of type: `<class 'torch.Tensor'>`\n",
      "of shape: `torch.Size([4096])`\n"
     ]
    }
   ],
   "source": [
    "# demonstration of how to access Token._.llama_vec embedding\n",
    "word_index = 9\n",
    "print(f\"\"\"Average of sentence-piece embeddings for: `{doc[word_index]}`\n",
    "at doc index: `{word_index}`\n",
    "is of type: `{type(doc[5]._.llama_vec)}`\n",
    "of shape: `{doc[5]._.llama_vec.shape}`\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad63911-137e-407f-b49a-763f53afb872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0018, -0.0038,  0.0010,  ..., -0.0090,  0.0027, -0.0038],\n",
       "        [ 0.0277, -0.0060,  0.0035,  ...,  0.0005, -0.0082,  0.0064],\n",
       "        [-0.0299, -0.0148, -0.0530,  ...,  0.0047, -0.0173, -0.0120],\n",
       "        ...,\n",
       "        [ 0.0133,  0.0078,  0.0081,  ...,  0.0051,  0.0067,  0.0248],\n",
       "        [ 0.0085,  0.0002,  0.0320,  ...,  0.0081, -0.0081, -0.0270],\n",
       "        [ 0.0003,  0.0029, -0.0126,  ...,  0.0014, -0.0019, -0.0064]],\n",
       "       dtype=torch.float16, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract hidden states from result\n",
    "hidden = lc.extract_embeddings(result[:-1],kind=\"hidden\")\n",
    "hidden[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d465e73f-46a3-481c-816e-f419cbb22afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [6.6260e-01, 3.3716e-01, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [5.4248e-01, 1.7432e-01, 2.8296e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [1.1169e-02, 5.6343e-03, 1.1162e-02,  ..., 1.1650e-02, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [6.0749e-04, 1.2960e-03, 4.7326e-04,  ..., 2.6436e-03, 2.0447e-01,\n",
       "         0.0000e+00],\n",
       "        [2.2984e-03, 1.6270e-03, 1.9798e-03,  ..., 6.3515e-03, 8.8013e-02,\n",
       "         1.8066e-01]], dtype=torch.float16, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract attentions from result\n",
    "attentions = lc.extract_embeddings(result,kind=\"attention\")\n",
    "attentions[0].squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179a13c9-b8cf-4fcb-8fcc-6620f8d78658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8387e-03, -3.8147e-03,  9.6130e-04,  ..., -9.0332e-03,\n",
       "           2.6550e-03, -3.7537e-03],\n",
       "         [ 2.7710e-02, -6.0425e-03,  3.4943e-03,  ...,  5.1117e-04,\n",
       "          -8.1787e-03,  6.4087e-03],\n",
       "         [-2.9907e-02, -1.4771e-02, -5.2979e-02,  ...,  4.7302e-03,\n",
       "          -1.7334e-02, -1.2024e-02],\n",
       "         ...,\n",
       "         [-2.9907e-02, -1.4771e-02, -5.2979e-02,  ...,  4.7302e-03,\n",
       "          -1.7334e-02, -1.2024e-02],\n",
       "         [-2.3315e-02, -1.8677e-02,  5.8594e-03,  ...,  1.7578e-02,\n",
       "          -2.0266e-05,  1.2390e-02],\n",
       "         [-1.4954e-03, -3.5095e-04, -1.7624e-03,  ...,  8.8882e-04,\n",
       "           1.6937e-03, -6.9427e-04]]], dtype=torch.float16,\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract both from result\n",
    "both = lc.extract_embeddings(result,kind=\"both\")\n",
    "both[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b556f7c-379c-4df0-8b10-7b09907aad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_base -> openai.base_url\n",
    "# openai.proxy -> openai.proxies (docs)\n",
    "# openai.InvalidRequestError -> openai.BadRequestError\n",
    "# openai.Audio.transcribe() -> client.audio.transcriptions.create()\n",
    "# openai.Audio.translate() -> client.audio.translations.create()\n",
    "# openai.ChatCompletion.create() -> client.chat.completions.create()\n",
    "# openai.Completion.create() -> client.completions.create()\n",
    "# openai.Edit.create() -> client.edits.create()\n",
    "# openai.Embedding.create() -> client.embeddings.create()\n",
    "# openai.File.create() -> client.files.create()\n",
    "# openai.File.list() -> client.files.list()\n",
    "# openai.File.retrieve() -> client.files.retrieve()\n",
    "# openai.File.download() -> client.files.retrieve_content()\n",
    "# openai.FineTune.cancel() -> client.fine_tunes.cancel()\n",
    "# openai.FineTune.list() -> client.fine_tunes.list()\n",
    "# openai.FineTune.list_events() -> client.fine_tunes.list_events()\n",
    "# openai.FineTune.stream_events() -> client.fine_tunes.list_events(stream=True)\n",
    "# openai.FineTune.retrieve() -> client.fine_tunes.retrieve()\n",
    "# openai.FineTune.delete() -> client.fine_tunes.delete()\n",
    "# openai.FineTune.create() -> client.fine_tunes.create()\n",
    "# openai.FineTuningJob.create() -> client.fine_tuning.jobs.create()\n",
    "# openai.FineTuningJob.cancel() -> client.fine_tuning.jobs.cancel()\n",
    "# openai.FineTuningJob.delete() -> client.fine_tuning.jobs.create()\n",
    "# openai.FineTuningJob.retrieve() -> client.fine_tuning.jobs.retrieve()\n",
    "# openai.FineTuningJob.list() -> client.fine_tuning.jobs.list()\n",
    "# openai.FineTuningJob.list_events() -> client.fine_tuning.jobs.list_events()\n",
    "# openai.Image.create() -> client.images.generate()\n",
    "# openai.Image.create_variation() -> client.images.create_variation()\n",
    "# openai.Image.create_edit() -> client.images.edit()\n",
    "# openai.Model.list() -> client.models.list()\n",
    "# openai.Model.delete() -> client.models.delete()\n",
    "# openai.Model.retrieve() -> client.models.retrieve()\n",
    "# openai.Moderation.create() -> client.moderations.create()\n",
    "# openai.api_resources -> openai.resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a23aeda-e830-4342-8249-19f2a15c5c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4-0613',\n",
       " 'gpt-4',\n",
       " 'gpt-4-vision-preview',\n",
       " 'gpt-4-1106-preview',\n",
       " 'gpt-4-0314']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI\"),\n",
    ")\n",
    "\n",
    "[mod['id'] for mod in client.models.list().model_dump()['data'] if mod[\"id\"].startswith(\"gpt-4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f51b4f-818a-4ad1-aea3-04a857c09d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psy_llm_chat as plc\n",
    "# analgous chat class to LlamaChat but for GPT 4\n",
    "# gpt-4 models\n",
    "model_name = 'gpt-4-0314' #from march 14\n",
    "# model_name = 'gpt-4-0613' #from june 13\n",
    "# model_name = 'gpt-4' #most recent\n",
    "\n",
    "# load chat class\n",
    "gptc = plc.GptChat(client, model=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa17e35d-7c48-47e3-ac35-27afe949004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: If you can hear me say hi.\n",
      "Assistant: As an AI text model, I cannot hear you. However, I can understand your text input and respond accordingly. So, hi!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  END_THIS_NOW\n"
     ]
    }
   ],
   "source": [
    "# chat with <<model_name>>, again input `END_THIS_NOW` to terminate the dialog and return the (List[Dict]) result\n",
    "result = gptc(test_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "febfe125-6883-4d0c-9848-7e6fdcb6ef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: If you can hear me say hi.\n",
      "Assistant: As an AI language model, I cannot hear or speak. However, I can understand and respond to text-based messages. If you have any questions or need assistance, feel free to ask.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'If you can hear me say hi.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'As an AI language model, I cannot hear or speak. However, I can understand and respond to text-based messages. If you have any questions or need assistance, feel free to ask.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptc.get_response(test_dialog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm_chat3]",
   "language": "python",
   "name": "conda-env-llm_chat3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
